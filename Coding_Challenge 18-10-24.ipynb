{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2b3295",
   "metadata": {},
   "source": [
    "# Implement a K-Nearest Neighbors (KNN) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8521336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def euclidean_distance(point1: Tuple[float, float], point2: Tuple[float, float]) -> float:\n",
    "    \"\"\"Calculate the Euclidean distance between two points.\"\"\"\n",
    "    return math.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "def knn_classifier(data_points: List[Tuple[float, float, str]], new_point: Tuple[float, float], k: int = 3) -> str:\n",
    "    \"\"\"KNN classifier to predict the label of the new point using k nearest neighbors.\"\"\"\n",
    "    \n",
    "    # Step 1: Calculate the Euclidean distance between the new point and all data points\n",
    "    distances = []\n",
    "    for point in data_points:\n",
    "        distance = euclidean_distance(new_point, (point[0], point[1]))\n",
    "        distances.append((distance, point[2]))  # Store the distance along with the label\n",
    "    \n",
    "    # Step 2: Sort the distances in ascending order\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Step 3: Get the labels of the k nearest neighbors\n",
    "    k_nearest_labels = [label for _, label in distances[:k]]\n",
    "    \n",
    "    # Step 4: Perform a majority vote to determine the most common label\n",
    "    most_common_label = Counter(k_nearest_labels).most_common(1)[0][0]\n",
    "    \n",
    "    return most_common_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47a3b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n"
     ]
    }
   ],
   "source": [
    "# Data points with their labels\n",
    "data_points = [\n",
    "    (1.0, 2.0, 'A'), \n",
    "    (2.0, 3.0, 'B'), \n",
    "    (3.0, 4.0, 'A'), \n",
    "    (5.0, 6.0, 'B'), \n",
    "    (1.5, 1.8, 'A')\n",
    "]\n",
    "\n",
    "# New point to classify\n",
    "new_point = (2.5, 3.5)\n",
    "\n",
    "# Predict the label for the new point using KNN\n",
    "predicted_label = knn_classifier(data_points, new_point, k=3)\n",
    "print(predicted_label) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee345a",
   "metadata": {},
   "source": [
    "# Remove Outliers from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5980955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import statistics\n",
    "\n",
    "def remove_outliers(data: List[float]) -> List[float]:\n",
    "    \"\"\"Removes outliers from the data. A number is considered an outlier if it is \n",
    "    more than 2 * standard deviation away from the mean of the list.\"\"\"\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Step 1: Calculate the mean and standard deviation\n",
    "    mean = statistics.mean(data)\n",
    "    std_dev = statistics.stdev(data)\n",
    "    \n",
    "    # Step 2: Define the threshold for outliers (mean Â± 2 * std_dev)\n",
    "    lower_bound = mean - 2 * std_dev\n",
    "    upper_bound = mean + 2 * std_dev\n",
    "    \n",
    "    print(f\"Mean: {mean}, Std Dev: {std_dev}\")\n",
    "    print(f\"Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
    "    \n",
    "    # Step 3: Remove any number outside the bounds\n",
    "    filtered_data = [x for x in data if lower_bound <= x <= upper_bound]\n",
    "    \n",
    "    print(f\"Filtered Data: {filtered_data}\")\n",
    "    \n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c24010a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 28.333333333333332, Std Dev: 35.223098481914775\n",
      "Lower Bound: -42.11286363049622, Upper Bound: 98.77953029716288\n",
      "Filtered Data: [10, 12, 14, 16, 18]\n",
      "Cleaned Data: [10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "data = [10, 12, 14, 16, 18, 100]\n",
    "cleaned_data = remove_outliers(data)\n",
    "print(\"Cleaned Data:\", cleaned_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96224c4",
   "metadata": {},
   "source": [
    "# 3. Optimize a Matrix Multiplication for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3b1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def matrix_multiply(mat1: List[List[int]], mat2: List[List[int]]) -> List[List[int]]:\n",
    "    # Check if matrices can be multiplied (columns in mat1 must equal rows in mat2)\n",
    "    if len(mat1[0]) != len(mat2):\n",
    "        raise ValueError(\"Incompatible matrices: Cannot multiply matrices with dimensions {}x{} and {}x{}.\".format(len(mat1), len(mat1[0]), len(mat2), len(mat2[0])))\n",
    "\n",
    "    # Initialize the result matrix with zeros (size: m x p)\n",
    "    result = [[0] * len(mat2[0]) for _ in range(len(mat1))]\n",
    "\n",
    "    # Perform matrix multiplication\n",
    "    for i in range(len(mat1)):  # iterate over rows of mat1\n",
    "        for j in range(len(mat2[0])):  # iterate over columns of mat2\n",
    "            for k in range(len(mat2)):  # iterate over rows of mat2 (or columns of mat1)\n",
    "                result[i][j] += mat1[i][k] * mat2[k][j]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "851c63e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 30, 33]\n",
      "[61, 68, 75]\n",
      "[95, 106, 117]\n"
     ]
    }
   ],
   "source": [
    "mat1 = [\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "]\n",
    "\n",
    "mat2 = [\n",
    "    [7, 8, 9],\n",
    "    [10, 11, 12]\n",
    "]\n",
    "\n",
    "result = matrix_multiply(mat1, mat2)\n",
    "for row in result:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af24b72",
   "metadata": {},
   "source": [
    "# 4. Word Embedding Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f231d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import math\n",
    "\n",
    "def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:\n",
    "    # Check if vectors have the same length\n",
    "    if len(vec1) != len(vec2):\n",
    "        raise ValueError(\"Vectors must have the same length.\")\n",
    "    \n",
    "    # Step 1: Compute dot product\n",
    "    dot_product = sum(v1 * v2 for v1, v2 in zip(vec1, vec2))\n",
    "    \n",
    "    # Step 2: Compute magnitudes of vec1 and vec2\n",
    "    magnitude_vec1 = math.sqrt(sum(v1 ** 2 for v1 in vec1))\n",
    "    magnitude_vec2 = math.sqrt(sum(v2 ** 2 for v2 in vec2))\n",
    "    \n",
    "    # Step 3: Handle zero magnitude (which means vector is 0, leading to undefined similarity)\n",
    "    if magnitude_vec1 == 0 or magnitude_vec2 == 0:\n",
    "        raise ValueError(\"One of the vectors has zero magnitude, so cosine similarity is undefined.\")\n",
    "    \n",
    "    # Step 4: Compute cosine similarity\n",
    "    cosine_sim = dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "    \n",
    "    return cosine_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c500293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9746318461970762\n"
     ]
    }
   ],
   "source": [
    "vec1 = [1.0, 2.0, 3.0]\n",
    "vec2 = [4.0, 5.0, 6.0]\n",
    "\n",
    "similarity = cosine_similarity(vec1, vec2)\n",
    "print(\"Cosine Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd269be",
   "metadata": {},
   "source": [
    "# 5. Implement a Min-Heap Using a Priority Queue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ab3f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class MinHeap:\n",
    "    def __init__(self):\n",
    "        # Initialize an empty list to store the heap\n",
    "        self.heap = []\n",
    "    \n",
    "    def insert(self, value: int) -> None:\n",
    "        \"\"\"Insert a value into the min-heap.\"\"\"\n",
    "        heapq.heappush(self.heap, value)\n",
    "    \n",
    "    def get_min(self) -> int:\n",
    "        \"\"\"Return the smallest value in the min-heap without removing it.\"\"\"\n",
    "        if not self.heap:\n",
    "            raise IndexError(\"Heap is empty.\")\n",
    "        return self.heap[0]\n",
    "    \n",
    "    def extract_min(self) -> int:\n",
    "        \"\"\"Remove and return the smallest value from the min-heap.\"\"\"\n",
    "        if not self.heap:\n",
    "            raise IndexError(\"Heap is empty.\")\n",
    "        return heapq.heappop(self.heap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d95a318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Element: 1\n",
      "Extracted Minimum: 1\n",
      "New Minimum Element: 3\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of MinHeap\n",
    "min_heap = MinHeap()\n",
    "\n",
    "# Insert elements into the heap\n",
    "min_heap.insert(5)\n",
    "min_heap.insert(3)\n",
    "min_heap.insert(8)\n",
    "min_heap.insert(1)\n",
    "\n",
    "# Get the minimum element\n",
    "print(\"Minimum Element:\", min_heap.get_min())  \n",
    "\n",
    "# Extract the minimum element\n",
    "print(\"Extracted Minimum:\", min_heap.extract_min())  \n",
    "\n",
    "# Get the new minimum element after extraction\n",
    "print(\"New Minimum Element:\", min_heap.get_min()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6be2e9",
   "metadata": {},
   "source": [
    "# 6. Implement a Support Vector Machine (SVM) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0e1a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def svm_classifier(data_points: List[Tuple[float, float, int]], new_point: Tuple[float, float]) -> int:\n",
    "    # Step 1: Define the hyperplane (manually setting weights and bias for simplicity)\n",
    "\n",
    "    # For simplicity, we'll use some predefined weights and bias\n",
    "    w = [1.0, -1.0] \n",
    "    b = 0.0         \n",
    "    \n",
    "    # Step 2: Calculate the decision function for the new point\n",
    "    decision_value = w[0] * new_point[0] + w[1] * new_point[1] + b\n",
    "    \n",
    "    # Step 3: Return the class based on the decision value\n",
    "    if decision_value >= 0:\n",
    "        return 1  # Class +1\n",
    "    else:\n",
    "        return -1  # Class -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f98a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 1\n"
     ]
    }
   ],
   "source": [
    "data_points = [\n",
    "    (1.0, 2.0, 1),    # (x, y, label)\n",
    "    (2.0, 3.0, 1),\n",
    "    (3.0, 3.0, -1),\n",
    "    (4.0, 1.0, -1)\n",
    "]\n",
    "\n",
    "# New point to classify\n",
    "new_point = (2.5, 2.5)\n",
    "\n",
    "# Call the SVM classifier\n",
    "predicted_label = svm_classifier(data_points, new_point)\n",
    "print(\"Predicted Label:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513dfcd",
   "metadata": {},
   "source": [
    "# 7. Calculate the Z-Score of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c0e53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def calculate_z_scores(data: List[float]) -> List[float]:\n",
    "    # Step 1: Calculate the mean of the data\n",
    "    mean = sum(data) / len(data)\n",
    "    \n",
    "    # Step 2: Calculate the standard deviation\n",
    "    variance = sum((x - mean) ** 2 for x in data) / len(data)\n",
    "    std_dev = variance ** 0.5\n",
    "    \n",
    "    # Step 3: Calculate the Z-score for each data point\n",
    "    z_scores = [(x - mean) / std_dev for x in data]\n",
    "    \n",
    "    return z_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8af46ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Scores: [-0.7328081543718783, -0.6820194704055105, -0.6312307864391427, -0.5804421024727748, -0.5296534185064071, 1.5526826241146732, 1.603471308081041]\n"
     ]
    }
   ],
   "source": [
    "data = [10, 12, 14, 16, 18, 100, 102]\n",
    "z_scores = calculate_z_scores(data)\n",
    "print(\"Z-Scores:\", z_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568e266",
   "metadata": {},
   "source": [
    "# 8. K-Means Clustering Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20b8f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "def euclidean_distance(p1: Tuple[float, float], p2: Tuple[float, float]) -> float:\n",
    "    # Calculate Euclidean distance between two points\n",
    "    return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2) ** 0.5\n",
    "\n",
    "def calculate_centroid(cluster: List[Tuple[float, float]]) -> Tuple[float, float]:\n",
    "    # Calculate the centroid (mean) of a cluster\n",
    "    x_coords = [point[0] for point in cluster]\n",
    "    y_coords = [point[1] for point in cluster]\n",
    "    return (sum(x_coords) / len(x_coords), sum(y_coords) / len(y_coords))\n",
    "\n",
    "def k_means_clustering(data_points: List[Tuple[float, float]], k: int) -> List[Tuple[float, float]]:\n",
    "    # Step 1: Randomly initialize k centroids from the data points\n",
    "    centroids = random.sample(data_points, k)\n",
    "    \n",
    "    for _ in range(10):  # Limit to 10 iterations for simplicity\n",
    "        clusters = [[] for _ in range(k)]\n",
    "        \n",
    "        # Step 2: Assign each point to the nearest centroid\n",
    "        for point in data_points:\n",
    "            distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
    "            closest_centroid_idx = distances.index(min(distances))\n",
    "            clusters[closest_centroid_idx].append(point)\n",
    "        \n",
    "        # Step 3: Update centroids based on the new cluster\n",
    "        centroids = [calculate_centroid(cluster) for cluster in clusters]\n",
    "    \n",
    "    return centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bf278a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Centroids: [(2.75, 3.75), (9.25, 9.25)]\n"
     ]
    }
   ],
   "source": [
    "data_points = [(1.0, 2.0), (2.0, 3.0), (3.0, 4.0), (5.0, 6.0), \n",
    "               (8.0, 8.0), (9.0, 10.0), (10.0, 10.0), (10.0, 9.0)]\n",
    "\n",
    "k = 2 \n",
    "centroids = k_means_clustering(data_points, k)\n",
    "print(\"Final Centroids:\", centroids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d2c40d",
   "metadata": {},
   "source": [
    "# 9. Evaluate Classification Model Using F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4992b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def f1_score(true_labels: List[int], predicted_labels: List[int]) -> float:\n",
    "    # Count True Positives (TP), False Positives (FP), and False Negatives (FN)\n",
    "    tp = sum(1 for true, pred in zip(true_labels, predicted_labels) if true == 1 and pred == 1)\n",
    "    fp = sum(1 for true, pred in zip(true_labels, predicted_labels) if true == 0 and pred == 1)\n",
    "    fn = sum(1 for true, pred in zip(true_labels, predicted_labels) if true == 1 and pred == 0)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca0563ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "true_labels = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
    "predicted_labels = [1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
    "\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33452e78",
   "metadata": {},
   "source": [
    "# 10. Visualize Data Distribution Using a Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ac7b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def create_histogram(data: List[float], bins: int) -> Dict[str, int]:\n",
    "    # Find the minimum and maximum values in the data\n",
    "    min_val = min(data)\n",
    "    max_val = max(data)\n",
    "    \n",
    "    # Calculate the width of each bin\n",
    "    bin_width = (max_val - min_val) / bins\n",
    "    \n",
    "    # Create an empty dictionary to store the histogram\n",
    "    histogram = {}\n",
    "    \n",
    "    # Create the bin ranges and initialize their counts to 0\n",
    "    for i in range(bins):\n",
    "        bin_start = min_val + i * bin_width\n",
    "        bin_end = bin_start + bin_width\n",
    "        bin_range = f\"{round(bin_start, 2)} - {round(bin_end, 2)}\"\n",
    "        histogram[bin_range] = 0\n",
    "    \n",
    "    # Assign each data point to the appropriate bin\n",
    "    for value in data:\n",
    "        bin_index = int((value - min_val) / bin_width)\n",
    "        # If the value is exactly max_val, put it in the last bin\n",
    "        if bin_index == bins:\n",
    "            bin_index -= 1\n",
    "        bin_start = min_val + bin_index * bin_width\n",
    "        bin_end = bin_start + bin_width\n",
    "        bin_range = f\"{round(bin_start, 2)} - {round(bin_end, 2)}\"\n",
    "        histogram[bin_range] += 1\n",
    "    \n",
    "    return histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "285023f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 - 3.25: 4\n",
      "3.25 - 5.5: 3\n",
      "5.5 - 7.75: 2\n",
      "7.75 - 10.0: 4\n"
     ]
    }
   ],
   "source": [
    "data = [1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 10]\n",
    "bins = 4\n",
    "\n",
    "hist = create_histogram(data, bins)\n",
    "for bin_range, count in hist.items():\n",
    "    print(f\"{bin_range}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b869921e",
   "metadata": {},
   "source": [
    "# 11. Implement a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12717d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label for [2, 2] is: B\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple, Any\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, data: List[Tuple[List[float], str]]):\n",
    "        \"\"\"Build the decision tree using the training data.\"\"\"\n",
    "        self.tree = self._build_tree(data)\n",
    "\n",
    "    def _build_tree(self, data: List[Tuple[List[float], str]]) -> Any:\n",
    "        \"\"\"Recursively build the decision tree.\"\"\"\n",
    "        labels = [label for _, label in data]\n",
    "        \n",
    "        # If all labels are the same, return that label (leaf node)\n",
    "        if len(set(labels)) == 1:\n",
    "            return labels[0]\n",
    "        \n",
    "        # If there are no features left, return the most common label\n",
    "        if not data:\n",
    "            return max(set(labels), key=labels.count)\n",
    "\n",
    "        # Find the best feature to split on\n",
    "        best_feature_index = self._best_feature_to_split(data)\n",
    "\n",
    "        # Create a tree node\n",
    "        tree = {\"feature_index\": best_feature_index, \"children\": {}}\n",
    "\n",
    "        # Split the data based on the best feature\n",
    "        feature_values = set([point[0][best_feature_index] for point in data])\n",
    "        for value in feature_values:\n",
    "            # Create sub-datasets for each value\n",
    "            subset = [point for point in data if point[0][best_feature_index] == value]\n",
    "            # Recursively build the tree for the subset\n",
    "            tree[\"children\"][value] = self._build_tree(subset)\n",
    "\n",
    "        return tree\n",
    "\n",
    "    def _best_feature_to_split(self, data: List[Tuple[List[float], str]]) -> int:\n",
    "        \"\"\"Find the best feature to split the data on.\"\"\"\n",
    "        # For simplicity, we can return the first feature\n",
    "        return 0  \n",
    "\n",
    "    def predict(self, point: List[float]) -> str:\n",
    "        \"\"\"Predict the label of a new point using the decision tree.\"\"\"\n",
    "        return self._predict(self.tree, point)\n",
    "\n",
    "    def _predict(self, tree: Any, point: List[float]) -> str:\n",
    "        \"\"\"Recursively predict the label for the given point.\"\"\"\n",
    "        if isinstance(tree, str): \n",
    "            return tree\n",
    "        \n",
    "        # Get the feature index to split on\n",
    "        feature_index = tree[\"feature_index\"]\n",
    "        feature_value = point[feature_index]\n",
    "        \n",
    "        # Traverse the tree\n",
    "        if feature_value in tree[\"children\"]:\n",
    "            return self._predict(tree[\"children\"][feature_value], point)\n",
    "        else:\n",
    "            return \"Unknown\"  \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Training data: (features, label)\n",
    "    data = [\n",
    "        ([1, 2], 'A'),\n",
    "        ([1, 3], 'A'),\n",
    "        ([2, 2], 'B'),\n",
    "        ([2, 3], 'B'),\n",
    "        ([3, 3], 'A'),\n",
    "    ]\n",
    "\n",
    "    # Create and train the decision tree\n",
    "    tree = DecisionTree()\n",
    "    tree.fit(data)\n",
    "\n",
    "    # Predicting a new point\n",
    "    new_point = [2, 2]\n",
    "    predicted_label = tree.predict(new_point)\n",
    "    print(\"Predicted label for\", new_point, \"is:\", predicted_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae5551a",
   "metadata": {},
   "source": [
    "# 12. Normalize Data Using Min-Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b30f634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data: [10, 15, 20, 25, 30]\n",
      "Normalized Data: [0.0, 0.25, 0.5, 0.75, 1.0]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "def min_max_normalization(data: List[float]) -> List[float]:\n",
    "    \"\"\"Normalize the data to a range between 0 and 1 using Min-Max scaling.\"\"\"\n",
    "    if not data:  # Check if the input list is empty\n",
    "        return []\n",
    "\n",
    "    min_value = min(data)\n",
    "    max_value = max(data)  \n",
    "\n",
    "    # Handle case where max_value equals min_value to avoid division by zero\n",
    "    if min_value == max_value:\n",
    "        return [0.0] * len(data) \n",
    "\n",
    "    # Normalize each value\n",
    "    normalized_data = [(value - min_value) / (max_value - min_value) for value in data]\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    data = [10, 15, 20, 25, 30]\n",
    "    normalized_data = min_max_normalization(data)\n",
    "    print(\"Original Data:\", data)\n",
    "    print(\"Normalized Data:\", normalized_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a41b0",
   "metadata": {},
   "source": [
    "# 13. Calculate Euclidean Distance Between Two Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "024cb6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean distance between [1.0, 2.0, 3.0] and [4.0, 5.0, 6.0] is: 5.196152422706632\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import math\n",
    "\n",
    "def euclidean_distance(point1: List[float], point2: List[float]) -> float:\n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError(\"Points must have the same number of dimensions\")\n",
    "\n",
    "    # Calculate the sum of squared differences\n",
    "    sum_squared_diff = sum((x - y) ** 2 for x, y in zip(point1, point2))\n",
    "\n",
    "    # Return the square root of the sum of squared differences\n",
    "    return math.sqrt(sum_squared_diff)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    point_a = [1.0, 2.0, 3.0]\n",
    "    point_b = [4.0, 5.0, 6.0]\n",
    "    distance = euclidean_distance(point_a, point_b)\n",
    "    print(f\"The Euclidean distance between {point_a} and {point_b} is: {distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1c87f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
